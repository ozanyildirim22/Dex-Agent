{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lMxWq42a_w8J",
        "outputId": "a9f2ca49-cda1-4372-c621-ba55bcb49a6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydantic==1.10.8\n",
            "  Downloading pydantic-1.10.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (146 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/146.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m112.6/146.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m143.4/146.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.4/146.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain==0.2.16\n",
            "  Downloading langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core==0.2.41\n",
            "  Downloading langchain_core-0.2.41-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting albumentations==1.3.0\n",
            "  Downloading albumentations-1.3.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting gradio==3.40.0\n",
            "  Downloading gradio-3.40.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting langchain-community==0.2.0\n",
            "  Downloading langchain_community-0.2.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Downloading pydantic-1.10.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.2.16-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.41-py3-none-any.whl (397 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.0/397.0 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albumentations-1.3.0-py3-none-any.whl (123 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-3.40.0-py3-none-any.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydantic, langchain-core, langchain-community, langchain, gradio, albumentations\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.9.2\n",
            "    Uninstalling pydantic-2.9.2:\n",
            "      Successfully uninstalled pydantic-2.9.2\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.4.15\n",
            "    Uninstalling albumentations-1.4.15:\n",
            "      Successfully uninstalled albumentations-1.4.15\n",
            "Successfully installed albumentations-1.3.0 gradio-3.40.0 langchain-0.2.16 langchain-community-0.2.0 langchain-core-0.2.41 pydantic-1.10.8\n"
          ]
        }
      ],
      "source": [
        "%pip install pydantic==1.10.8 langchain==0.2.16 langchain-core==0.2.41 albumentations==1.3.0 gradio==3.40.0 langchain-community==0.2.0 --no-deps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jmAh6ZQG_5x9",
        "outputId": "44002f5e-8005-45d6-b958-cf8b64e6ab68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-nvidia-ai-endpoints\n",
            "  Downloading langchain_nvidia_ai_endpoints-0.3.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from langchain-nvidia-ai-endpoints) (3.10.10)\n",
            "Collecting langchain-core<0.4,>=0.3.0 (from langchain-nvidia-ai-endpoints)\n",
            "  Downloading langchain_core-0.3.10-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain-nvidia-ai-endpoints) (10.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.14.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (4.0.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (6.0.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.125 (from langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints)\n",
            "  Downloading langsmith-0.1.135-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (24.1)\n",
            "Collecting pydantic<3.0.0,>=2.5.2 (from langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints)\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (4.12.2)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (2.32.3)\n",
            "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (2.23.4)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (0.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (1.2.2)\n",
            "Downloading langchain_nvidia_ai_endpoints-0.3.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.10-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.4/404.4 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langsmith-0.1.135-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m968.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, orjson, jsonpointer, h11, requests-toolbelt, pydantic, jsonpatch, httpcore, httpx, langsmith, langchain-core, langchain-nvidia-ai-endpoints\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.8\n",
            "    Uninstalling pydantic-1.10.8:\n",
            "      Successfully uninstalled pydantic-1.10.8\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.2.41\n",
            "    Uninstalling langchain-core-0.2.41:\n",
            "      Successfully uninstalled langchain-core-0.2.41\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 3.40.0 requires aiofiles<24.0,>=22.0, which is not installed.\n",
            "gradio 3.40.0 requires fastapi, which is not installed.\n",
            "gradio 3.40.0 requires ffmpy, which is not installed.\n",
            "gradio 3.40.0 requires gradio-client>=0.4.0, which is not installed.\n",
            "gradio 3.40.0 requires pydub, which is not installed.\n",
            "gradio 3.40.0 requires python-multipart, which is not installed.\n",
            "gradio 3.40.0 requires semantic-version~=2.0, which is not installed.\n",
            "gradio 3.40.0 requires uvicorn>=0.14.0, which is not installed.\n",
            "gradio 3.40.0 requires websockets<12.0,>=10.0, which is not installed.\n",
            "langchain 0.2.16 requires langchain-text-splitters<0.3.0,>=0.2.0, which is not installed.\n",
            "langchain-community 0.2.0 requires dataclasses-json<0.7,>=0.5.7, which is not installed.\n",
            "gradio 3.40.0 requires markupsafe~=2.0, but you have markupsafe 3.0.1 which is incompatible.\n",
            "gradio 3.40.0 requires mdit-py-plugins<=0.3.3, but you have mdit-py-plugins 0.4.2 which is incompatible.\n",
            "langchain 0.2.16 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 0.3.10 which is incompatible.\n",
            "langchain-community 0.2.0 requires langchain-core<0.3.0,>=0.2.0, but you have langchain-core 0.3.10 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.10 langchain-nvidia-ai-endpoints-0.3.0 langsmith-0.1.135 orjson-3.10.7 pydantic-2.9.2 requests-toolbelt-1.0.0 tenacity-8.5.0\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain-nvidia-ai-endpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSx530JIXOAa"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b3iAssJAUZH"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrnNkAnFASTQ"
      },
      "outputs": [],
      "source": [
        "os.environ[\"NVIDIA_API_KEY\"] = \"nvida-api-key\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXUhfOOXSx3_"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "def get_data_of_coin(db):\n",
        "  text=db['coin_name']\n",
        "  response = requests.get(\n",
        "    \"https://api.dexscreener.com/latest/dex/search?q=\"+text+\"\",\n",
        "    headers={},\n",
        "  )\n",
        "  main_data = response.json()\n",
        "  coin=main_data['pairs'][0]\n",
        "  print(coin)\n",
        "  return coin\n",
        "\n",
        "coin_data_getter = RunnableLambda(get_data_of_coin)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_to_string_f(db):\n",
        "\n",
        "  result =\"\"\n",
        "  if \"price\" in db['message']:\n",
        "    result+= f\"The price of the {db['coin_name']} is {db['data']['priceUsd']}\"\n",
        "  if \"volume\" in db['message']:\n",
        "    result+= f\"The volume of the {db['coin_name']} is {db['data']['volume']['h24']}\"\n",
        "  if \"liquidity\" in db['message']:\n",
        "    result+= f\"The liquidity of the {db['coin_name']} is {db['data']['liquidity']}\"\n",
        "  if \"market cap\" in db['message']:\n",
        "    result+= f\"The market cap of the {db['coin_name']} is {db['data']['marketCap']}\"\n",
        "  if \"price change\" in db['message']:\n",
        "    result+= f\"The price change of the {db['coin_name']} is {db['data']['priceChange']['h24']}\"\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "data_to_string_r = RunnableLambda(data_to_string_f)"
      ],
      "metadata": {
        "id": "pUyaiEOZdBQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kY5LYPf-Rkl"
      },
      "outputs": [],
      "source": [
        "instruct_llm = ChatNVIDIA(model=\"meta/llama-3.1-405b-instruct\") | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2QpVZLJEaWbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9nWiQPOAXGR",
        "outputId": "a0ae4363-91a5-4d1e-f6c0-c1f945eb49ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'm a Blockchain agent! How can I help you?\n",
            "\n",
            "[ Human ]: Tell me about the liquidity of the medusa coin\n",
            "\n",
            "[ Agent ]: \n",
            "{'chainId': 'solana', 'dexId': 'raydium', 'url': 'https://dexscreener.com/solana/9k8sezpkxdehqf9sq1erzc8udtlu4widrryfr381crru', 'pairAddress': '9K8sEZpkxDeHqf9Sq1eRzc8UDtLU4widRrYFR381crrU', 'baseToken': {'address': 'Fosp9yoXQBdx8YqyURZePYzgpCnxp9XsfnQq69DRvvU4', 'name': 'MEDUSA', 'symbol': 'MEDUSA'}, 'quoteToken': {'address': 'So11111111111111111111111111111111111111112', 'name': 'Wrapped SOL', 'symbol': 'SOL'}, 'priceNative': '0.00003233', 'priceUsd': '0.005040', 'txns': {'m5': {'buys': 90, 'sells': 99}, 'h1': {'buys': 1730, 'sells': 1279}, 'h6': {'buys': 17203, 'sells': 14345}, 'h24': {'buys': 22791, 'sells': 19220}}, 'volume': {'h24': 19631809.77, 'h6': 16030865.7, 'h1': 1493871.13, 'm5': 56066.95}, 'priceChange': {'m5': 12.77, 'h1': -18.6, 'h6': 192, 'h24': 8328}, 'liquidity': {'usd': 294283.07, 'base': 29157464, 'quote': 944.9019}, 'fdv': 5040984, 'marketCap': 5040984, 'pairCreatedAt': 1728910701000, 'info': {'imageUrl': 'https://dd.dexscreener.com/ds-data/tokens/solana/Fosp9yoXQBdx8YqyURZePYzgpCnxp9XsfnQq69DRvvU4.png', 'websites': [], 'socials': [{'type': 'twitter', 'url': 'https://x.com/BrokenEmoAI'}, {'type': 'telegram', 'url': 'https://t.me/medusasolana'}]}, 'boosts': {'active': 500}}\n",
            "The Medusa coin has a liquidity of approximately $294,283.07 USD. Would you like to know more about the market performance of Medusa or is there something else I can help you with?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain.schema.runnable.passthrough import RunnableAssign\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"You are a blockchain chatbot.Please answer the user question:{message} while acting like Blockchain chatbot\"\n",
        "    \"Please help them with their question if it is ethical and relevant using only the context: {context}\"\n",
        "    \"(This is just for you, do not mention context,do not explain anything)\"\n",
        "\n",
        ")\n",
        "\n",
        "assist_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Based on the user message:{message} get the coin user mentioned\"\n",
        "    \"Do not say things like 'Here is your response', just say the coin\"\n",
        "    \"For example if user message is 'I want to know about diddy coin, then you should output diddy'\"\n",
        "\n",
        ")\n",
        "\n",
        "assist_chain =assist_prompt|instruct_llm\n",
        "\n",
        "chat_chain=(\n",
        "    RunnableAssign({'coin_name':assist_chain})\n",
        "    |RunnableAssign({'data':coin_data_getter})\n",
        "    |RunnableAssign({'context':data_to_string_r})\n",
        "    |prompt|instruct_llm\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Hello! I'm a Blockchain agent! How can I help you?\")\n",
        "\n",
        "for i in range(8):\n",
        "  history = [[None, \"Hello! I'm a Blockchain agent! How can I help you?\"]]\n",
        "  message=input(\"\\n[ Human ]: \")\n",
        "  print(\"\\n[ Agent ]: \")\n",
        "  history_entry = [message, \"\"]\n",
        "  for token in chat_chain.invoke({'message':message}):\n",
        "    print(token, end='')\n",
        "    history_entry[1] += token\n",
        "  history += [history_entry]\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}